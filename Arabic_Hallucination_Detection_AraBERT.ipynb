{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# file_path = \"Arabic LLMs Hallucination-OSACT2024-Train.txt\"  # Update path if needed\n",
        "# df = pd.read_csv(file_path, sep=\"\\t\")\n",
        "\n",
        "\n",
        "# df['is_hallucinated'] = df['label'].apply(lambda x: 1 if x in ['F1', 'NF'] else 0)\n",
        "\n",
        "# output_path = \"Corrected_Arabic_LLMs_Hallucination_Train.xlsx\"\n",
        "# df.to_excel(output_path, index=False)\n",
        "\n",
        "# print(\"Saved successfully to:\", output_path)\n"
      ],
      "metadata": {
        "id": "m83n4ZTtNws6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "os.environ[\"WANDB_MODE\"] = \"offline\""
      ],
      "metadata": {
        "id": "pl6KuGQRn20W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers datasets evaluate\n"
      ],
      "metadata": {
        "id": "rA_f-d-dfizz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
        "\n",
        "print(\"ðŸŽ‰ Transformers imported successfully!\")"
      ],
      "metadata": {
        "id": "Ch1EL06jcqba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers, datasets, evaluate\n",
        "print(f\"Transformers: {transformers.__version__}\")  # Should be ~4.xx.x\n",
        "print(f\"Datasets: {datasets.__version__}\")          # Should be ~2.xx.x\n",
        "print(f\"Evaluate: {evaluate.__version__}\")          # Should be ~0.4.x"
      ],
      "metadata": {
        "id": "joHFD7XWPyZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
        "from datasets import Dataset, DatasetDict\n",
        "import evaluate\n",
        "import random\n",
        "import os"
      ],
      "metadata": {
        "id": "SAQgtHGsL5Cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)"
      ],
      "metadata": {
        "id": "T-BV0R_gMSWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "OJZCyNTDMUoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"aubmindlab/bert-base-arabertv02\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "id": "YTfKDE7VMXI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_excel('Corrected_Arabic_LLMs_Hallucination_Train.xlsx')\n"
      ],
      "metadata": {
        "id": "RmPryifhRBMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.head())"
      ],
      "metadata": {
        "id": "Ma51E9lYRxsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['is_hallucinated'] = train_df['is_hallucinated'].astype(int)"
      ],
      "metadata": {
        "id": "y5rW4uDsMZUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = train_df['is_hallucinated'].tolist()"
      ],
      "metadata": {
        "id": "N7eiScCkMbao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    train_df['claim'].tolist(),\n",
        "    train_df['is_hallucinated'].tolist(),\n",
        "    test_size=0.2,\n",
        "    random_state=SEED,\n",
        "    stratify=train_df['is_hallucinated']\n",
        ")"
      ],
      "metadata": {
        "id": "QhQVj8PeMdTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    tokenized = tokenizer(examples['text'], truncation=True, padding='max_length', max_length=128)\n",
        "    if 'labels' in examples:\n",
        "        tokenized['labels'] = examples['labels']\n",
        "    return tokenized"
      ],
      "metadata": {
        "id": "EUqt1HlvMf8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Dataset.from_dict({'text': train_texts, 'labels': train_labels})\n",
        "val_dataset = Dataset.from_dict({'text': val_texts, 'labels': val_labels})"
      ],
      "metadata": {
        "id": "BxElf9y1MiVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = DatasetDict({\n",
        "    'train': train_dataset.map(preprocess_function, batched=True),\n",
        "    'validation': val_dataset.map(preprocess_function, batched=True)\n",
        "})"
      ],
      "metadata": {
        "id": "41h1eJr-Mj2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'], output_all_columns=True)\n",
        "\n",
        "# Define model\n",
        "num_labels = 2\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_labels).to(device)\n",
        "\n",
        "# Metrics computation\n",
        "metric = evaluate.load(\"accuracy\")"
      ],
      "metadata": {
        "id": "35vJF9ALMmI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return {\n",
        "        'macro_f1': f1_score(labels, predictions, average='macro'),\n",
        "        'accuracy': accuracy_score(labels, predictions)\n",
        "    }"
      ],
      "metadata": {
        "id": "eKwCal3yMoOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "labels = np.array([0, 1])\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels), y=train_labels)\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model.to(device)\n",
        "class_weights = class_weights.to(device)\n"
      ],
      "metadata": {
        "id": "ol442eEkiQJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "print(Counter(train_labels))"
      ],
      "metadata": {
        "id": "VB661OfLAMMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "import torch.nn as nn\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "        loss_fct = nn.CrossEntropyLoss(weight=class_weights)\n",
        "        loss = loss_fct(logits, labels)\n",
        "        return (loss, outputs) if return_outputs else loss\n"
      ],
      "metadata": {
        "id": "eg3ON-F8wr-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./arabert_classification',\n",
        "    eval_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=15,\n",
        "    weight_decay=0.01,\n",
        "    # no_cuda=True,\n",
        "    seed=42,\n",
        "    lr_scheduler_type='linear',\n",
        "    warmup_ratio= 0.1,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='accuracy',\n",
        "    greater_is_better=True,\n",
        "    report_to=[],\n",
        ")\n"
      ],
      "metadata": {
        "id": "_JNRRkv9MqYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "trainer = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=datasets['train'],\n",
        "    eval_dataset=datasets['validation'],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    # callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        ")"
      ],
      "metadata": {
        "id": "ZWilkcmZMsAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n"
      ],
      "metadata": {
        "id": "ljfR4Pee4B5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "Gf1TDoN8MuS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = trainer.predict(datasets['validation'])\n",
        "print(np.unique(preds.predictions.argmax(axis=1), return_counts=True))\n"
      ],
      "metadata": {
        "id": "jkn3Gd9y11CV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model('./arabert_finetuned')"
      ],
      "metadata": {
        "id": "5qAqyRCEMwo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('Arabic LLMs Hallucination-OSACT2024-Test-NoLabels.txt', sep='\\t')\n",
        "test_texts = test_df['claim'].tolist()\n",
        "test_ids = test_df['claim_id'].tolist()\n",
        "\n",
        "test_dataset = Dataset.from_dict({'text': test_texts})\n",
        "test_dataset = test_dataset.map(preprocess_function, batched=True)\n",
        "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])"
      ],
      "metadata": {
        "id": "PCQfijdPM0wL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = trainer.predict(test_dataset)\n",
        "predicted_labels = np.argmax(predictions.predictions, axis=-1)\n",
        "predicted_labels_decoded = ['hallucinated' if label == 1 else 'not_hallucinated' for label in predicted_labels]"
      ],
      "metadata": {
        "id": "4CZaMV58M19r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_df = pd.DataFrame({\n",
        "    'claim_id': test_ids,\n",
        "    'predicted_label': predicted_labels_decoded\n",
        "})"
      ],
      "metadata": {
        "id": "W8wiB3FHM43e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_df.to_csv('arabert_predictions.csv', index=False)\n",
        "\n",
        "print(\"Inference completed. Predictions saved to 'arabert_predictions.csv'.\")"
      ],
      "metadata": {
        "id": "mPLDFcZiM621"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "preds = trainer.predict(datasets['validation'])\n",
        "\n",
        "y_pred = np.argmax(preds.predictions, axis=-1)\n",
        "y_true = preds.label_ids\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "print(f\"âœ… Validation Accuracy: {accuracy:.4f}\")\n",
        "print(f\"âœ… Validation Macro F1: {macro_f1:.4f}\")\n",
        "\n",
        "report = classification_report(y_true, y_pred, target_names=['Not Hallucinated', 'Hallucinated'])\n",
        "print(\"\\nðŸ“Š Classification Report:\\n\", report)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "df_cm = pd.DataFrame(cm, index=['Not Hallucinated', 'Hallucinated'], columns=['Predicted Not', 'Predicted Yes'])\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(df_cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('ðŸ§© Confusion Matrix (Validation Set)')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jRvk-Bc1JZLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NsdG-CHDQGmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q78fvI4QQIoe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}